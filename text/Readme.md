# Using chatGPT

I found to use the openAI API I need to pay because there is no more free usage.
I setup the code but without payement I cannot realy confirm if it is working. 

My API is hidden in .secret file with the help of dotenv library.

# Using Hugging Face

# OpenAI GPT
The model is trained in the Toronto Book Corpus.
It contains over 7,000 unique unpublished books from a variety of genres including Adventure,
Fantasy, and Romance. Crucially, it contains long stretches of contiguous text, which allows the
generative model to learn to condition on long-range information.

Itâ€™s a causal (unidirectional) transformer. These models have a unidirectional context, as they take the previous word in the sentence into account while predicting the next word. Their primary objective is to predict the next token, considering the context of the words to the left within a sentence. Technically Decoder the model employs Decoder-only models, also known as Auto-Regressive Models, rely solely on a decoder to perform tasks like Text Generation.

Examples of Causal Language Modeling or Decoder-Only models include GPT, GPT-2, GPT-3, BLOOM, and PaLM.



Paper: Improving Language Understanding by Generative Pre-Training

## Example:
Model="open-ai"
```
[{'generated_text': 'Does money buy happiness ?, for me. for both of us! " she cried aloud, shaking with the force of the emotion. \n " well, my dear, " he began, a smile playing about his lips, " that is exactly what'}, {'generated_text': "Does money buy happiness ?, \n if a person wants to feel better than they have in years, she wants to show you that money is not always happy. money has a need, a desire. people are always in need... \n i haven't"}]
```

Model="gpt2" *Language modeling trained on a very large corpus of ~40 GB of text data.*
```
[{'generated_text': 'Does money buy happiness ?, but what about saving people from despair? Does money buy happiness?\n\nWhat is happiness, and what does it mean? Why should money be used to buy happiness?\n\nWhy do humans value lives by doing everything'}, {'generated_text': 'Does money buy happiness ?, this is not the answer and therefore there is hardly any chance that we will ever know the answers.\n\nOne very logical approach to solving this problem would use the very simple problem of finding the money flow in terms of'}]

[{'generated_text': 'Does money buy happiness ?'}, {'generated_text': 'Does money buy happiness ?\n\nI would love to see more people like me get into the field with the game. It would be cool if my friends got into it. There are a very few people like me who have come through the door and'}]

[{'generated_text': 'A step by step recipe to make bolognese pasta:\n\n1 tablespoon vegetable oil\n\n1 teaspoon salt\n\n1 tablespoon Worcestershire sauce\n\n1 tablespoon Worcestershire sauce 3 large eggs, beaten\n\n5'}, {'generated_text': 'A step by step recipe to make bolognese pasta:\n\nMix together the yogurt, flour and water and combine with your hands until thickened and smooth. Add the onion and cook until translucent, 2 to 3 minutes. Add the garlic'}]
```

This result is not very convincing. Output is often not representative how people interact.
# DialogGPT
DialoGPT (dialogue generative pre-trained transformer) is provided by Microsoft.
Trained on 147M conversation-like exchanges extracted from Reddit comment chains over a period spanning from 2005 through 2017. Unlike GPT-2, which is trained on general text data,  DialoGPT is trained on 147M multi-turn dialogues extracted from Reddit discussion threads.
Like GPT-2, DialoGPT is formulated as an autoregressive (AR) language model.
## Example :
```
**User:** Does money buy happiness?

**DialoGPT:** Money buys happiness, but it also buys a lot of things that make you happy.

**User:** What is the best way to buy happiness?

**DialoGPT:** Money. Money buys happiness.

**User:** What about gold?

**DialoGPT:** Gold is a good investment.
```

It is not very suitable than using chatgpt.
we can observe that sentences generated by DialoGPT are diverse and contain information specific to the source prompt, analogous to the outputs that GPT-2 generates.

Paper: DIALOGPT : Large-Scale Generative Pre-training for Conversational Response Generation

# Flan-T5
Unlike previous model this one is Encoder-decoder models, also known as Sequence-to-Sequence Models, employ both an encoder and a decoder to perform tasks such as Machine Translation and Summarization.
Flan-T5 developed by Google Research is the instruction fine-tuned version of T5 or Text-to-Text Transfer Transformer Language Model.
FLAN-T5 emerges as a compelling alternative to GPT-3, showcasing advantages in computational efficiency, task performance, cost-effectiveness, and customization ease. Nevertheless, determining the superior model depends significantly on the specific task or application at hand.




## Example :
```
prompt: "Does money buy happiness ?"
answer : no

prompt : "Does money buy happiness?,"
answer : ['money is a source of happiness.']

prompt : "A step by step recipe to make bolognese pasta:"
answer : ['Pour a cup of bolognese into a large bowl and add the pasta to the bowl.']
```

# Quick conclusion : 
Language models produce responses for all inputs, but their outputs may be unreliable, particularly when faced with novel or unconventional inputs. This unreliability poses challenges for utilizing the model in real-world applications where precision is essential. These models are trained on extensive text data and might inherit biases embedded in that data. As a consequence, they can generate inaccurate outputs and potentially perpetuate detrimental stereotypes.
